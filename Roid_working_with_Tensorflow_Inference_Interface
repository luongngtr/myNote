(References: 
https://www.tensorflow.org/get_started/mnist/beginners
https://aqibsaeed.github.io/2017-05-02-deploying-tensorflow-model-andorid-device-human-activity-recognition/
https://omid.al/posts/2017-02-20-Tutorial-Build-Your-First-Tensorflow-Android-App.html
)

// STEP 1
// Download the prebuilt libraries (file named 'libtensorflow_inference.so') of Tensorflow for android 
https://ci.tensorflow.org/view/Nightly/job/nightly-android/
// (For example: https://ci.tensorflow.org/view/Nightly/job/nightly-android/100/artifact/)
// Or use the following instruction to build it again
https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/android


// STEP 2
// Create a new project in Android Studio
// Copy and past the file named 'libandroid_tensorflow_inference_java.jar' in the folder called 'app/libs'
// Similarly, copy and past 'libtensorflow_inference.so' into a collection of subfolders 
//      (arm64-v8a, armeabi-v7a, x86, x86_64) of the folder 'app/libs' 
// The structure of 'app/libs' as follows
libs
|-----libandroid_tensorflow_inference_java.jar
|-----arm64-v8a
      |-----libtensorflow_inference.so
|-----armeabi-v7a
      |-----libtensorflow_inference.so
|-----x86
      |-----libtensorflow_inference.so
|-----x86_64
      |-----libtensorflow_inference.so
      
// STEP 3
// Let the project knows where of these library files
//      by adding the following lines to the file called 'app/build.gradle'
--------------------------------------
android {
....
  sourceSets {
          main {
              jniLibs.srcDirs = ['libs']
          }
      }
...
}
--------------------------------------

// STEP 4
// Use Python code editor (for example Spyder of Anaconda) to create a model file of sensor network
// For convenience, the outputs and inputs should have two dimensions of a vector, for example, [1,784] so that 
// 	when we freeze the graph and use it in Android Studio, we can easily declare the dimension of variable
//	as {1, 784}.
---------------------------------------------------------------------
// In some .py file
---------------------------------------------------------------------
import tensorflow as tf

I = tf.placeholder(tf.float32, shape=[None,3], name='I') # input
W = tf.Variable(tf.zeros(shape=[3,2]), dtype=tf.float32, name='W') # weights
b = tf.Variable(tf.zeros(shape=[2]), dtype=tf.float32, name='b') # biases
O = tf.nn.relu(tf.matmul(I, W) + b, name='O') # activation / output

saver = tf.train.Saver()
init_op = tf.global_variables_initializer()

with tf.Session() as session:
	/** 
		------- Model training code goes here ------
	**/
	tf.train.write_graph(session.graph_def, '.', '../har.pbtxt')  
	saver.save(session,save_path = "../har.ckpt")
---------------------------------------------------------------------
// In another .py file
---------------------------------------------------------------------
from tensorflow.python.tools import freeze_graph
from tensorflow.python.tools import optimize_for_inference_lib

freeze_graph.freeze_graph(input_graph = "../har.pbtxt",  input_saver = "",
             input_binary = False, input_checkpoint = "../har.ckpt", output_node_names = "y_",
             restore_op_name = "save/restore_all", filename_tensor_name = "save/Const:0",
             output_graph = "frozen_har.pb", clear_devices = True, initializer_nodes = "")

input_graph_def = tf.GraphDef()
with tf.gfile.Open(output_frozen_graph_name, "r") as f:
    data = f.read()
    input_graph_def.ParseFromString(data)

output_graph_def = optimize_for_inference_lib.optimize_for_inference(
        input_graph_def,
        ["input"], 
        ["y_"],
        tf.float32.as_datatype_enum)

f = tf.gfile.FastGFile("optimized_har.pb", "w")
f.write(output_graph_def.SerializeToString())
---------------------------------------------------------------------
// The output file name of the above python code is 'optimized_har.pb'
// Put this file in the folder called 'app/src/main/assets'
src
|-----main
      |-----assets
            |-----optimized_har.pb


// STEP 5
// Use Java to work with the .so library and the .pb python model 
---------------------------------------------------------------------
// In 'MainActivity.java'
---------------------------------------------------------------------
import org.tensorflow.contrib.android.TensorFlowInferenceInterface;

public class MainActivity extends AppCompatActivity {

private static final String MODEL_FILE = "file:///android_asset/optimized_tfdroid.pb";
    private static final String INPUT_NODE = "I";
    private static final String OUTPUT_NODE = "O";

    private static final long[] INPUT_SIZE = {1,3};

    private TensorFlowInferenceInterface inferenceInterface;

    static {
        System.loadLibrary("tensorflow_inference");
    }

    @Override
    protected void onCreate(Bundle savedInstanceState) {
    ...
    inferenceInterface = new TensorFlowInferenceInterface(getAssets(), MODEL_FILE);    
    ...
    float[] inputFloats = {num1, num2, num3};
    inferenceInterface.feed(INPUT_NODE, inputFloats, INPUT_SIZE);
    inferenceInterface.run(new String[] {OUTPUT_NODE});

    float[] result = {0, 0};
    inferenceInterface.fetch(OUTPUT_NODE, result);
    ...
    }
...
}    
---------------------------------------------------------------------

// Another example of java code in STEP5 
---------------------------------------------------------------------
// File name: <project_name>/app/src/main/java/TFConnector.java 
// (This file is in the same folder of MainActivity
// so that we can use this file in MainActivity without any import)
---------------------------------------------------------------------
package com.luongfamily.pictonum;
import android.content.Context;
import org.tensorflow.contrib.android.TensorFlowInferenceInterface;
import java.util.Random;

public class TFConnector {    
    final String MODEL_FILE = "optimized_mymnist.pb";
    final String MODEL_FILE3 = "optimized_Assignment5_1.pb";
    final String INPUT_NODE = "I";
    final long[] INPUT_SIZE = {1, 784};
    final String INPUT_NODE2 = "I2";
    final long[] INPUT_SIZE2 = {1, 1};
    final String INPUT_NODE3 = "z";
    final long[] INPUT_SIZE3 = {1, 100};
    final String INPUT_NODE4 = "y";
    final long[] INPUT_SIZE4 = {1, 10};
    final String OUTPUT_NODE = "O";
   
    TFFrozenGraphProcessor my_processor001;
    TFFrozenGraphProcessor my_processor002;

    Context context;

    public TFConnector(Context context) {
        this.context = context;
        this.my_processor001 = new TFFrozenGraphProcessor(this.context, this.MODEL_FILE,
                new String[]{this.INPUT_NODE, this.INPUT_NODE2}, new String[]{this.OUTPUT_NODE}, new long[]{this.INPUT_SIZE[1], this.INPUT_SIZE2[1]});

        this.my_processor002 = new TFFrozenGraphProcessor(this.context, this.MODEL_FILE3,
                new String[]{this.INPUT_NODE3, this.INPUT_NODE4}, new String[]{this.OUTPUT_NODE}, new long[]{this.INPUT_SIZE3[1], this.INPUT_SIZE4[1]});
    }

    static {
        System.loadLibrary("tensorflow_inference");
    }

    public float[] func001(float[] inputArray) {        
        float[][] myResult = {{0, 0, 0, 0, 0, 0, 0, 0, 0, 0}};
        float[] inputArray2 = new float[1];
        inputArray2[0] = (float) 0.2;
        myResult = my_processor001.execute(new float[][]{inputArray, inputArray2}, myResult);
        return myResult[0];
    }

    public float[] func002(float[] inputArray3) {       
        float[] inputArray4 = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
        Random myrandom = new Random();
        inputArray4[myrandom.nextInt(10)] = 1;
        float[][] myResult3 = new float[1][784];
        myResult3 = my_processor002.execute(new float[][]{inputArray3, inputArray4}, myResult3);
        return myResult3[0];
    }

}

class TFFrozenGraphProcessor {
    final String MODEL_FILE;
    final String[] INPUT_NODES;
    final long[] INPUT_SIZES;
    final String[] OUTPUT_NODES;

    TensorFlowInferenceInterface inferenceInterface;
    Context context;

    public TFFrozenGraphProcessor(Context context, String fileName, String[] inputNodes, String[] outputNodes, long[] inputSizes) {
        this.context = context;
        this.MODEL_FILE = "file:///android_asset/" + fileName;
        this.INPUT_NODES = inputNodes;
        this.OUTPUT_NODES = outputNodes;
        this.INPUT_SIZES = inputSizes;
    }

    static {
        System.loadLibrary("tensorflow_inference");
    }

    public float[][] execute(float[][] feedData, float[][] resultStorage) {        
        this.inferenceInterface = new TensorFlowInferenceInterface(this.context.getAssets(), this.MODEL_FILE);        
        for (int i=0; i < this.INPUT_NODES.length; i++){            
            this.inferenceInterface.feed(this.INPUT_NODES[i], feedData[i], new long[]{1, this.INPUT_SIZES[i]});
        }

        float[][] resultArrays = new float[resultStorage.length][resultStorage[0].length];
        for (int i=0; i < this.OUTPUT_NODES.length; i++){            
            this.inferenceInterface.run(new String[]{this.OUTPUT_NODES[i]});
            float[] myResult = resultStorage[i];
            this.inferenceInterface.fetch(this.OUTPUT_NODES[i], myResult);
            resultArrays[i] = myResult;
        }

        return resultArrays;
    }

}
---------------------------------------------------------------------

---------------------------------------------------------------------
// File name: <project_name>/app/src/main/java/MainActivity.java 
---------------------------------------------------------------------
package com.luongfamily.pictonum;

import ...

public class MainActivity extends AppCompatActivity {    

    ********************************************************************************************* */
    public TFConnector my_worker = new TFConnector(this);
    //**********************************************************************************************  


    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.activity_main);
	
        ...
	float[] inputArray = new float[intArray.length];
	float[] myResult = my_worker.func001(inputArray);
	...
	float[] myResult3 = new float[784];
	float[] myResult3 = my_worker.func002(inputArray3);
        ...        
                
    }

    @Override
    protected void onActivityResult(int requestCode, int resultCode, Intent data) {
        switch (requestCode){
            case 7:
                if(resultCode==RESULT_OK){
                    PathHolder = data.getData();

                    path_view.setText(PathHolder.getPath());

                    // Display the image
                    try {
                        myInputStream = getContentResolver().openInputStream(PathHolder);
                        myBitmap = BitmapFactory.decodeStream(myInputStream);
                        image_view.setImageBitmap(myBitmap);

                        //Toast.makeText(MainActivity.this, PathHolder.getPath(), Toast.LENGTH_LONG).show();

                    } catch(FileNotFoundException e) {

                        Toast.makeText(MainActivity.this, "File not found", Toast.LENGTH_LONG).show();

                    }
                }
        }
    }

}
---------------------------------------------------------------------








